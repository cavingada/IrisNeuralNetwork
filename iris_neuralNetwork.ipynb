{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LjLO0CbTJwWj"
      },
      "outputs": [],
      "source": [
        "#author @ Cavin Gada\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "iris = load_iris() \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ToVeaZWkg95m"
      },
      "outputs": [],
      "source": [
        "# Load Data and Preprocess Data\n",
        "\n",
        "x = iris.data\n",
        "y_preprocessed = iris.target\n",
        "y = np.array([[0,0,0]]) # we initialize to have 1 random data element such that dimensions work when appending. \n",
        "\n",
        "\n",
        "# preprocess data by the following convention (I was recommended by a friend to consider formatting my target values like this):\n",
        "# 1. 0 ('Setosa') = [1,0,0]\n",
        "# 2. 1 ('Versicolor') = [0,1,0]\n",
        "# 3. 2 ('Virginica') = [0,0,1]\n",
        "\n",
        "for i in range(y_preprocessed.shape[0]):\n",
        "  if y_preprocessed[i] == 0:\n",
        "    y = np.append(y, [[1,0,0]],axis=0)\n",
        "  elif y_preprocessed[i] == 1:\n",
        "    y = np.append(y, [[0,1,0]],axis=0)\n",
        "  else:\n",
        "    y = np.append(y,[[0,0,1]],axis=0)\n",
        "\n",
        "y=y[1:] # get rid of that first random element we made. \n",
        "\n",
        "# 18% of the dataset will be used for testing\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.18)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NJiuGp9KtASj"
      },
      "outputs": [],
      "source": [
        "# functions to do training and predictions\n",
        "\n",
        "def randomizeWeights(layers): \n",
        "  # we do layers-1 iterations since weights are used as a connection from one layer to another\n",
        "  weightMatrix = []\n",
        "\n",
        "  for i in range(len(layers)-1):\n",
        "\n",
        "    currentNodes = layers[i+1]\n",
        "    prevNodes = layers[i] # add 1 dimension for bias\n",
        "\n",
        "    # create a matrix of weights corresponding to the transitioning layers. (m x n, where m is the current layer and n is previous)\n",
        "    weight = np.random.randn(currentNodes, prevNodes)\n",
        "\n",
        "    # append the matrix to a list of matrices\n",
        "    weightMatrix.append(np.matrix(weight))\n",
        "\n",
        "  return weightMatrix\n",
        "\n",
        "\n",
        "def forward_propagation(x, w, layers):\n",
        "  activation_matrix = [] # let the first activation function be equal to the input. This will be useful when iterating backwards (for shape reasons). \n",
        "  activation_matrix.append([x])\n",
        "  currentLayer = x # the first layer is considered the input. \n",
        "  for i in range(len(w)):\n",
        "    # the following is exemplified on slides and https://dev.to/shamdasani/build-a-flexible-neural-network-with-backpropagation-in-python\n",
        "    # we need to keep forward propogating through each layer, so we go through every weight element and respectively update the layer. \n",
        "    z = np.dot(currentLayer, np.transpose(w[i]))\n",
        "    z2 = sig(z)\n",
        "    activation_matrix.append(z2) # must save activation function for when we do backpropogation\n",
        "    currentLayer = z2\n",
        "\n",
        "  #the activation matrix consists of all the activation functions at each intersection between layers. \n",
        "  return activation_matrix\n",
        "\n",
        "def backward_propagation(x, y, w, layers, activation_matrix, learning_rate):\n",
        "\n",
        "  # final error\n",
        "  o_error = np.matrix(y-activation_matrix[len(activation_matrix)-1]) \n",
        "\n",
        "  for i in range(len(w), 0, -1):\n",
        "    # current activation function\n",
        "    curr = activation_matrix[i]\n",
        "    # previous activation function\n",
        "    prev = activation_matrix[i-1]\n",
        "\n",
        "    # applied derivative of sigmoid to error. \n",
        "    o_delta = np.multiply(o_error, sigmoidPrime(curr))\n",
        "\n",
        "    # updating current layer error\n",
        "    o_error = np.dot(o_delta, w[i-1])\n",
        "\n",
        "    # weight adjustment. we must update the weight of the next layer (backwards). \n",
        "    w[i-1] = w[i-1] + (np.multiply(o_delta.T, prev)*learning_rate)\n",
        "\n",
        "  # return the weight that should be the new weight\n",
        "  return w\n",
        "\n",
        "def training_func(x_train, y_train, layers, learning_rate, epoch_amount):\n",
        "  w = randomizeWeights(layers) \n",
        "  for i in range(epoch_amount):\n",
        "    for i in range(len(y_train)):\n",
        "\n",
        "      # i-th training data\n",
        "      xi = x_train[i]\n",
        "      yi = y_train[i]\n",
        "\n",
        "      # activation functions through forward propogation\n",
        "      act = forward_propagation(xi,w,layers)\n",
        "\n",
        "      # weight update through back-propogation. note that back propogation will take current w and add to it. \n",
        "      w = backward_propagation(xi, yi, w, layers, act, learning_rate)\n",
        "\n",
        "  # returned the trained weight\n",
        "  return w\n",
        "\n",
        "def pred(xi, w, layers):\n",
        "\n",
        "  # must forward propogate, then find the last the activation function and compare outputed values. \n",
        "  last_activation = forward_propagation(xi,w,layers)[-1]\n",
        "  predictions = np.asarray(last_activation).flatten()\n",
        "  \n",
        "  most_likely = max(predictions)\n",
        "\n",
        "  # if most likely is 0 ('Setosa'), return [1,0,0]\n",
        "  if most_likely == predictions[0]:\n",
        "    return np.array([1,0,0])\n",
        "  # if most likely is 1 ('Versicolor'), return [0,1,0]\n",
        "  if most_likely == predictions[1]:\n",
        "    return np.array([0,1,0])\n",
        "  # if most likely is 2 ('Virginica'), return [0,0,1]\n",
        "  if most_likely == predictions[2]:\n",
        "    return np.array([0,0,1])\n",
        "\n",
        "def proportion_correct(x_data, y_data, w, layers):\n",
        "  numCorrect = 0\n",
        "  \n",
        "  for i in range(len(x_data)):\n",
        "\n",
        "    prediction = pred(x_data[i], w, layers)\n",
        "\n",
        "    if np.array_equal(prediction, y_data[i]):\n",
        "      numCorrect+=1\n",
        "\n",
        "  return numCorrect/len(x_data)\n",
        "\n",
        "def sig(n):\n",
        "    denominator = 1 + np.exp(0-n)\n",
        "    return 1.0/denominator\n",
        "\n",
        "def sigmoidPrime(s):\n",
        "    # must use numpy multiply for shape\n",
        "    return np.multiply(s, 1-s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "v9Sh5dQIppvj",
        "outputId": "8c016342-dd8a-4613-8f01-8ca8d01f440b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 Hidden layer with five nodes: \n",
            "Accuracy on train set is: 0.975609756097561\n",
            "Accuracy on test set is: 0.9259259259259259\n",
            "\n",
            "2 Hidden layer with six and eight nodes respectively: \n",
            "Accuracy on train set is: 0.967479674796748\n",
            "Accuracy on test set is: 0.9629629629629629\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "' Note: On rare occasions, my algorithm seems a little unreliable, where I recieve extremely low accuracy. This is quite possible due to\\nthe fact that we only have a small amount of data to do our learning with. With just 30% of the dataset being trained, it leaves\\nroom for error. \\n\\nHowever, for the most part, when the training is complete, I have noticed accuracies in the high 90% ranges. \\n\\nWhen comparing the 1 hidden layer model with the 2 hidden layers model, I noticed that in general, the two hidden layer model\\nperforms better. It performs \"better\" in a few ways:\\n  1. sometimes it has higher accuracies in both training and test set\\n  2. sometimes it only has higher accuracy on the test set (and perhaps a lower accuracy on the train set, indicating it is not\\n  overfitting the train data)\\n  3. sometimes it has higher accuracy on the train set, but similar accuracy on the test set. \\n  \\nOne fall back of my model is that the comparison between part a and b isn\\'t strong due to the fact that the initial weights will be\\ndifferent since they are randomized. Even though they are from a normal distribution, this could still cause high variance / false conclusions.\\n\\nAnother fall back is that perhaps the dataset is too small to introduce additional hidden layers. \\nOverall, it seems very difficult to tweak my model settings to keep a consistent accuracy every time my code is run. More specifically,\\nI do not really know how many hidden layers I should implement and with how many nodes in each to achieve consistently better\\nresults. I guess these are all problems I will learn how to solve in a future class :) ! '"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# PART A - 1 hidden layer with 5 nodes. \n",
        "\n",
        "print(\"1 Hidden layer with five nodes: \")\n",
        "layers = [4,5,3]\n",
        "w = training_func(x_train, y_train, layers, .1, 100)\n",
        "\n",
        "print(\"Accuracy on train set is: \" + str(proportion_correct(x_train, y_train, w, layers)))\n",
        "print(\"Accuracy on test set is: \" + str(proportion_correct(x_test, y_test, w, layers)))\n",
        "\n",
        "# PART B - 2 hidden layers with 6 and 8 nodes respectively. \n",
        "print(\"\\n\"+\"2 Hidden layer with six and eight nodes respectively: \")\n",
        "layers2 = [4,6,8,3]\n",
        "w2 = training_func(x_train, y_train, layers2, .1, 100)\n",
        "\n",
        "print(\"Accuracy on train set is: \" + str(proportion_correct(x_train, y_train, w2, layers2)))\n",
        "print(\"Accuracy on test set is: \" + str(proportion_correct(x_test, y_test, w2, layers2)))\n",
        "\n",
        "# findings:\n",
        "print(\"\\n\")\n",
        "\n",
        "\"\"\" Note: On rare occasions, my algorithm seems a little unreliable, where I recieve extremely low accuracy. This is quite possible due to\n",
        "the fact that we only have a small amount of data to do our learning with. With just 30% of the dataset being trained, it leaves\n",
        "room for error. \n",
        "\n",
        "However, for the most part, when the training is complete, I have noticed accuracies in the high 90% ranges. \n",
        "\n",
        "When comparing the 1 hidden layer model with the 2 hidden layers model, I noticed that in general, the two hidden layer model\n",
        "performs better. It performs \"better\" in a few ways:\n",
        "  1. sometimes it has higher accuracies in both training and test set\n",
        "  2. sometimes it only has higher accuracy on the test set (and perhaps a lower accuracy on the train set, indicating it is not\n",
        "  overfitting the train data)\n",
        "  3. sometimes it has higher accuracy on the train set, but similar accuracy on the test set. \n",
        "  \n",
        "One fall back of my model is that the comparison between part a and b isn't strong due to the fact that the initial weights will be\n",
        "different since they are randomized. Even though they are from a normal distribution, this could still cause high variance / false conclusions.\n",
        "\n",
        "Another fall back is that perhaps the dataset is too small to introduce additional hidden layers. \n",
        "Overall, it seems very difficult to tweak my model settings to keep a consistent accuracy every time my code is run. More specifically,\n",
        "I do not really know how many hidden layers I should implement and with how many nodes in each to achieve consistently better\n",
        "results. I guess these are all problems I will learn how to solve in a future class :) ! \"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "iris-neuralNetwork.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "d339a2a8c50b423644d93202ec801c8d3e3572f2d49108f6f93dfd237da3c203"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
